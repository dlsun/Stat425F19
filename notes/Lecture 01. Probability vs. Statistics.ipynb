{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability vs. Statistics\n",
    "\n",
    "What's probability got to do with statistics? Probability seems to be about games of chance, while statistics is about answering questions with data. How could they possibly be related?\n",
    "\n",
    "In statistics, we typically answer questions by assuming that data is generated from some random process.\n",
    "\n",
    "- In probability, we know the model and want to know what kind of data is likely to be generated.\n",
    "- In statistics, we have observed the data and want to answer questions about the model that generated it.\n",
    "\n",
    "In other words, probability and statistical inference are inverses of one another, as shown in the following diagram.\n",
    "\n",
    "![](img/prob_stat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q symbulate\n",
    "from symbulate import *\n",
    "NSIM = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Coin Tossing\n",
    "\n",
    "A coin is tossed 100 times.\n",
    "\n",
    "**Probability Question:** Suppose the coin has probability $0.5$ of coming up heads. What is the probability of observing 60 heads in the 100 tosses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = heads, 0 = tails\n",
    "model = BoxModel([0, 1], size=100, replace=True)\n",
    "model.sim(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding up the 0s and 1s gives the number of 1s (i.e., heads)\n",
    "X = RV(model, sum)\n",
    "X.sim(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate many instances and count how many are equal to 60.\n",
    "nsim = 10000\n",
    "X.sim(NSIM).count_eq(60) / NSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistics Question:** The coin may or may not be fair; it has some probability $p$ of coming up heads. But we observed 60 heads in 100 tosses. Based on this data, how do we estimate $p$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, $\\hat p = 60 / 100 = 0.6$. Is this estimate good or not? It's hard to say for certain whether any individual estimate is good. After all, what if the coin had come up heads 100 / 100 times, which is theoretically possible (although highly improbable). In that case, the estimate would be $\\hat p = 100 / 100 = 1$, which would probably be a terrible estimate.\n",
    "\n",
    "Even though we cannot evaluate individual estimates, we can evaluate the _procedure_ for coming up with the estimate, given data. This procedure is called the **estimator**.\n",
    "\n",
    "The procedure that we followed in coming up with $\\hat p = 0.6$ is this: take the number of heads in the data and divide by the number of tosses. Let's evaluate this estimator by simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose the coin is fair (p = 0.5)\n",
    "model = BoxModel([0, 1], size=100, replace=True)\n",
    "\n",
    "# Define the estimator\n",
    "def estimator(data):\n",
    "    # number of heads divided by the number of tosses\n",
    "    return sum(data) / len(data)\n",
    "p_hat = RV(model, estimator)\n",
    "\n",
    "# Now simulate many estimates.\n",
    "p_hat.sim(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot of these estimates.\n",
    "p_hat.sim(NSIM).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulated the data from a model where the true probability of heads was $p = 0.5$. We see that the estimated probability is not always $0.5$ exactly. It is sometimes more, sometimes less. But in expectation, it is equal to $0.5$. Let's check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat.sim(NSIM).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between this expectation and the truth is called the **bias** of the estimator.\n",
    "\n",
    "$$ \\text{bias} = E[\\text{estimate} ] - \\text{truth} $$\n",
    "\n",
    "The bias of $\\hat p$ is $0$ (at least when the true $p = 0.5$). We call an estimator **unbiased** if it has a bias of $0$. So the simulation suggests that $\\hat p$ is unbiased when $p = 0.5$. However, the simulation is not conclusive, nor does it provide evidence that $\\hat p$ is unbiased for any other value of the true $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: The German Tank Problem\n",
    "\n",
    "In World War II, the Allies wanted to know how many German tanks there were. Fortunately for them, each German tank had a serial number that corresponded to its position on the production line. For simplicity, suppose the first tank had a serial number of 1, the second tank a serial number of 2, and so on. If it were possible to see all the tanks, then the number of tanks would simply be the largest serial number.\n",
    "\n",
    "However, the Allies did not see all the German tanks. Instead, each time they encountered a German tank, they would secretly record the serial number. We'll assume that they were equally likely to encounter any of the existing German tanks. That is, if there are $N$ tanks, all of them had probability $1 / N$ of being encountered. We'll also assume that no tank could be encountered twice.\n",
    "\n",
    "**Probability question:** Suppose there were $N = 271$ tanks, of which the Allies encounter 10. What is the probability that the maximum serial number will be 221 _or greater_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoxModel(list(range(1, 272)), size=10, replace=False)\n",
    "\n",
    "# calculate the maximum\n",
    "X = RV(model, max)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistics question:** There are $N$ tanks. We encounter 10 tanks, whose serial numbers are\n",
    "\n",
    "193, 221, 129, 31, 169, 6, 33, 30, 151, 192.\n",
    "\n",
    "One possible estimator of $N$ is the maximum serial number. So based on this data, our estimate of $N$ would be $\\hat N = 221$. Is this a good estimator or not? Estimate its bias using simulation. (You will need to assume some value of $N$ in your simulation.) Is it unbiased for that value of $N$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you come up with a different estimator that is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
